---
title: "IST 5535 HW10: Predicting Count of Bike Rentals"
author: "Sayantan Majumdar"
date: "`r Sys.Date()`"
output: 
  html_document:
    number_sections: false
---
  ```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo=FALSE}
rm(list = ls())
```

### Task A: Data Manipulation

#### 1. Read the dataset into a data frame. Show the structure of the dataset.

```{r}
data <- read.csv('DC_Bike_Rentals.csv')
str(data)
knitr::kable(summary(data))
```

#### 2. A very important step in predictive analytics is to represent different scales of measurement correctly in the dataset. What variables in the dataset should be represented as categorical variables? List them in the box. Transform those variables identified above into factors.

The categorial variables are season, holiday, workingday, and weather.

```{r}
data$season <- as.factor(data$season)
data$holiday <- as.factor(data$holiday)
data$workingday <- as.factor(data$workingday)
data$weather <- as.factor(data$weather)
str(data)
```

#### 3.	Use 30-70% data partition strategy, with 30% of data used as test data.

```{r}
library(caret)
library(parallel)
library(doParallel)
cl <- makePSOCKcluster(detectCores() - 1)
registerDoParallel(cl)

set.seed(0)
train_index <- createDataPartition(data$count, p = .7, 
                                   list = F)
train_data <- data[train_index,]
test_data  <- data[-train_index,]
nrow(train_data)
nrow(test_data)
```

### Task B: Predictive Modeling 

#### 1.	Train a regression tree to predict count of bike rental on the training set. Prune the regression tree by using a best parameter identified through a cross-validation. Train the pruned regression model.

##### Original regression tree

```{r}
library(tree)

count_rt <- tree(count ~ ., data = train_data)
plot(count_rt)
text(count_rt, cex = 0.5, col = 'red')
summary(count_rt)
```

##### Pruned Regression Tree

```{r}
cv_count <- cv.tree(count_rt)
plot(cv_count$size, cv_count$dev, type = 'b', log = 'y', 
     xlab = 'Tree Size', ylab = 'Deviance')
```

Here, we see that for tree size = 13, the minimum deviance (number of misclassifcations) is obtained. So, there is no need to prune the decision tree. 

#### 2.	Train a random forest model to predict count of bike rental on the training set. Use a 10-fold cross-validation to run a parameter tuning process to find the optimal value of parameter “mtry”. Fit the final random forest model with the optimal mtry on the whole training set.

```{r}
library(randomForest)

count_rf <- randomForest(count ~ ., data = train_data,
                         mtry = 5, importance = T)
count_rf
```

##### Optimizing mtry

```{r}
num_predictors <- ncol(train_data) - 1
tuneGrid <- data.frame(mtry = 1: num_predictors)
print(tuneGrid)
control <- trainControl(method = 'repeatedcv',
                        number = 10, repeats = 1)
set.seed(0)
rf_tuned <- train(count ~ ., data = train_data,
                  method = 'rf',
                  trControl = control,
                  tuneGrid = tuneGrid)
print(rf_tuned)
plot(rf_tuned)
```

##### Final RF model

```{r}
count_rf <- randomForest(count ~ ., data = train_data,
                         mtry = 9, importance = T)
count_rf
varImpPlot(count_rf)
```

#### 3.	Train a support vector machine model to predict count of bike rental on the training set. The svm() method in the e1071 can also be used for regression problems. Use a 10-fold cross-validation to run a parameter tuning process to find the optimal kernel among linear, RBF, and polynomial kernels. Fit the final SVM model with the optimal kernel on the whole training set.

```{r}
library(e1071)

preprocessParams <- preProcess(train_data, 
                               method = 
                                 c("scale", "center"))
print(preprocessParams)
train_scaled <- predict(preprocessParams, train_data)
test_scaled <- predict(preprocessParams, test_data)

svm_cv <- function(data, response, num_folds, kernel_type) {
  set.seed(0)
  f <- as.formula(paste(response, '~ .'))
  if (kernel_type == 'radial') {
  tune_svm <- tune(svm, f, data = data, 
                   kernel = 'radial', 
                   tunecontrol = 
                     tune.control(
                       cross = num_folds, 
                       sampling = "cross"), 
                   ranges = list(cost = 10 ^ (-2: 2), 
                                 gamma = 10 ^ (-2: 2)))
  } else if (kernel_type == 'linear') {
    tune_svm <- tune(svm, f, data = data, 
                     kernel = 'linear', 
                     tunecontrol = 
                       tune.control(
                         cross = num_folds, 
                         sampling = "cross"), 
                     ranges = list(cost = 10 ^ (-2: 2)))
  } else {
    tune_svm <- tune(svm, f, data = data, 
                     kernel = 'polynomial', 
                     degree = 2, 
                     tunecontrol = 
                       tune.control(
                         cross = num_folds, 
                         sampling = "cross"), 
                     ranges = list(cost = 10 ^ (-2: 2)))
  }
  print(summary(tune_svm))
  print(tune_svm$best.parameters)
  print(tune_svm$best.performance)
  return(tune_svm)
}

svm_cv_caret <- function(data, response, num_folds, repeats, kernel_type) {
  set.seed(0)
  f <- as.formula(paste(response, '~ .'))
  tuneGrid <- data.frame(C = 10 ^ (-2: 2))
  if (kernel_type == 'svmRadial') {
    tuneGrid <- data.frame(C = 10 ^ (-2: 2), 
                           sigma = 10 ^ (-2: 2))
  } else if (kernel_type == 'svmPoly') {
    tuneGrid <- data.frame(C = 10 ^ (-2: 2), 
                           degree = (1: 5),
                           scale = 10 ^ (-4: 0))
  }
  print(tuneGrid)
  control <- trainControl(method = 'repeatedcv',
                          number = num_folds,
                          repeats = repeats)
  svm_tuned <- train(f, data = data,
                     method = kernel_type,
                     trControl = control,
                     tuneGrid = tuneGrid)
  print(svm_tuned)
  print(svm_tuned$bestTune)
  plot(svm_tuned)
  return(svm_tuned)
}
```

Using 10-fold cross validation to fine tune SVM kernels.

##### Linear Kernel

```{r}
tune_svm_linear <- svm_cv_caret(train_scaled, 'count',
                                10, 1, 'svmLinear')
```

##### Radial (RBF) Kernel

```{r}
tune_svm_radial <- svm_cv_caret(train_scaled, 'count',
                                10, 1, 'svmRadial')
```

##### Polynomial Kernel

```{r}
tune_svm_poly <- svm_cv_caret(train_scaled, 'count',
                        10, 1, 'svmPoly')
```

##### Final SVM Model

```{r}
count_svm <- svm(count ~ ., data = train_scaled,
                 kernel = 'radial', cost = 1, gamma = 1,
                 scale = T)
```

#### 4.	Use test dataset to evaluate the performance of your final models. Organize model comparison in a data frame.

##### Pruned Decision Tree Performance

```{r}
rt_yhat <- predict(count_rt, newdata = test_data)
rt_results <- postResample(rt_yhat, test_data$count)
plot(rt_yhat, test_data$count)
abline(0, 1)
```

##### Random Forest Performance

```{r}
rf_yhat <- predict(count_rf, newdata = test_data)
rf_results <- postResample(rf_yhat, test_data$count)
plot(rf_yhat, test_data$count)
abline(0, 1)
```

##### SVM Performance
```{r}
svm_yhat <- predict(count_svm, newdata = test_scaled)
svm_yhat <- svm_yhat * sd(test_data$count) + mean(test_data$count)
svm_results <- postResample(svm_yhat, test_data$count)
plot(svm_yhat, test_data$count)
abline(0, 1)
```

##### Model Evaluation

```{r}
final_df = data.frame(Model =
                        c('Pruned Regression Tree',
                          'Random Forests', 'SVM'),
                          RMSE = c(rt_results[["RMSE"]],
                                   rf_results[["RMSE"]],
                                   svm_results[["RMSE"]]),
                          R2 = c(rt_results[["Rsquared"]],
                                 rf_results[["Rsquared"]],
                                 svm_results[["Rsquared"]]),
                          MAE = c(rt_results[["MAE"]],
                                  rf_results[["MAE"]],
                                  svm_results[["MAE"]]))
print(final_df)
stopCluster(cl)
```
